{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import torch\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "svoc = en_core_web_sm.load()\n",
    "import numpy as np\n",
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datao = pd.read_pickle(\"~/OneDrive/kph/processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     5403\n",
       "4     4737\n",
       "2     3903\n",
       "5     2703\n",
       "1     1883\n",
       "6     1032\n",
       "0      746\n",
       "7      305\n",
       "8      120\n",
       "9       46\n",
       "10      35\n",
       "11      17\n",
       "13       8\n",
       "12       6\n",
       "15       5\n",
       "14       3\n",
       "16       3\n",
       "17       2\n",
       "22       2\n",
       "18       1\n",
       "Name: ext perc, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out less interesting keywords\n",
    "datao['ext perc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose everything larger than 3 as the training and testing data set\n",
    "datatrain = datao[datao['ext perc']>=3]\n",
    "datatest = datao[datao['ext perc']<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train, test, validate data set\n",
    "def prepare_csv(df_train, df_test,VAL_RATIO, seed=250):\n",
    "    idx = np.arange(df_train.shape[0])\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(idx)\n",
    "    val_size = int(len(idx) * VAL_RATIO)\n",
    "    df_train.iloc[idx[val_size:], :].to_csv(\n",
    "        \"~/OneDrive/kph/ttd/train.csv\", index=False)\n",
    "    df_train.iloc[idx[:val_size], :].to_csv(\n",
    "        \"~/OneDrive/kph/ttd/val.csv\", index=False)\n",
    "    df_test.to_csv(\"~/OneDrive/kph/ttd/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_csv(datatrain.loc[:,['SRC','TRG']], datatest.loc[:,['SRC','TRG']],0.2, seed=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizertrg = lambda x: x.split()\n",
    "def tokenizersrc(text): # create a tokenizer function\n",
    "    return [tok.text for tok in svoc.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(sequential=True, tokenize=tokenizersrc)\n",
    "TRG = Field(sequential=True, tokenize=tokenizertrg, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fields = [('SRC', SRC), ('TRG', TRG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = TabularDataset.splits(\n",
    "    path='~/OneDrive/kph/ttd/', train='train.csv',\n",
    "    validation='val.csv', test='test.csv', format='csv',\n",
    "    fields=data_fields,skip_header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first version with fixed embeddings\n",
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2196016/2196017 [03:35<00:00, 10178.84it/s]\n"
     ]
    }
   ],
   "source": [
    "embvec = vocab.GloVe(name='840B', dim=300,cache='/home/pding/Documents/glove/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train, vectors=embvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.vocab.set_vectors(vectors.stoi, vectors.vectors, vectors.dim)\n",
    "#embedding = nn.Embedding(n_embed, embed_dim).from_pretrained(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_iter = data.BucketIterator(\n",
    "    dataset=mt_train, batch_size=32,\n",
    "    sort_key=lambda x: len(x.comment_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keyphrases extraction",
   "language": "python",
   "name": "kphextr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
