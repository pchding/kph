{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "import torchtext\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embvec = torchtext.vocab.GloVe(name='840B', dim=300,cache='/home/pding/Documents/glove/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "svoc = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datao = pd.read_pickle(\"~/OneDrive/kph/processed2.pkl\")\n",
    "datatrain = datao[datao['ext perc']>=3]\n",
    "datatest = datao[datao['ext perc']<3]\n",
    "# separate train and validate \n",
    "VAL_RATIO = 0.2\n",
    "dtrain = datatrain.loc[:,['SRC','TRG']]\n",
    "dtraink = datatrain.loc[:,['SRC','TRG','keywords','ext perc']]\n",
    "seed=250\n",
    "idx = np.arange(datatrain.shape[0])\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(idx)\n",
    "val_size = int(len(idx) * VAL_RATIO)\n",
    "df_train = dtrain.iloc[idx[val_size:], :]\n",
    "df_val = dtrain.iloc[idx[:val_size], :]\n",
    "df_val_k = dtraink.iloc[idx[:val_size], :]\n",
    "df_test = datatest.loc[:,['SRC','TRG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizertrg = lambda x: x.split()\n",
    "def tokenizersrc(text): # create a tokenizer function\n",
    "    return [tok.text for tok in svoc.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(df_train, datafields):\n",
    "    examples = []\n",
    "    words = []\n",
    "    labels = []\n",
    "    for pmid in df_train.index:\n",
    "        words = tokenizersrc(df_train.loc[pmid,'SRC'])\n",
    "        labels = tokenizertrg(df_train.loc[pmid,'TRG'])\n",
    "        examples.append(torchtext.data.Example.fromlist([words, labels], datafields))\n",
    "    return torchtext.data.Dataset(examples, datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "\n",
    "class RNNCRFTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, text_field, label_field, emb_dim, rnn_size, update_pretrained=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        voc_size = len(text_field.vocab)\n",
    "        self.n_labels = len(label_field.vocab)       \n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, emb_dim)\n",
    "        if text_field.vocab.vectors is not None:\n",
    "            self.embedding.weight = torch.nn.Parameter(text_field.vocab.vectors, \n",
    "                                                       requires_grad=update_pretrained)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=emb_dim, hidden_size=rnn_size, \n",
    "                          bidirectional=True, num_layers=1)\n",
    "\n",
    "        self.top_layer = nn.Linear(2*rnn_size, self.n_labels)\n",
    " \n",
    "        self.pad_word_id = text_field.vocab.stoi[text_field.pad_token]\n",
    "        self.pad_label_id = label_field.vocab.stoi[label_field.pad_token]\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "#        self.crf = ConditionalRandomField(self.n_labels, label_encoding=\"BIO\",\n",
    "#                                          idx2tag=text_field.vocab.itos\n",
    "#                                         )\n",
    "    def compute_outputs(self, sentences):\n",
    "        embedded = self.embedding(sentences)\n",
    "        rnn_out, _ = self.rnn(embedded)\n",
    "        out = self.top_layer(rnn_out)\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences)\n",
    "        mask0 = sentences != self.pad_word_id\n",
    "        mask = mask0.byte()\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "        return -self.crf(scores, labels, mask=mask)\n",
    "            \n",
    "    def predict(self, sentences):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences)\n",
    "        mask0 = sentences != self.pad_word_id\n",
    "        mask = mask0.byte()\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        return self.crf.decode(scores, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(init_token='<bos>', eos_token='<eos>', sequential=True, lower=False)\n",
    "LABEL = torchtext.data.Field(init_token='<bos>', eos_token='<eos>', sequential=True, unk_token=None)\n",
    "fields = [('text', TEXT), ('label', LABEL)]\n",
    "device = 'cuda'\n",
    "use_pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using pre-trained word embeddings.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNNCRFTagger(\n",
       "  (embedding): Embedding(72288, 300)\n",
       "  (rnn): LSTM(300, 85, bidirectional=True)\n",
       "  (top_layer): Linear(in_features=170, out_features=6, bias=True)\n",
       "  (crf): CRF(num_tags=6)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples = read_data(df_train, fields)\n",
    "valid_examples = read_data(df_val, fields)\n",
    "# Load the pre-trained embeddings that come with the torchtext library.\n",
    "if use_pretrained:\n",
    "    print('We are using pre-trained word embeddings.')\n",
    "    TEXT.build_vocab(train_examples, vectors=embvec)\n",
    "else:  \n",
    "    print('We are training word embeddings from scratch.')\n",
    "    TEXT.build_vocab(train_examples, max_size=5000)\n",
    "LABEL.build_vocab(train_examples)\n",
    "# Create one of the models defined above.\n",
    "#self.model = RNNTagger(self.TEXT, self.LABEL, emb_dim=300, rnn_size=128, update_pretrained=False)\n",
    "model0 = RNNCRFTagger(TEXT, LABEL, emb_dim=300, rnn_size=85, update_pretrained=False)\n",
    "\n",
    "model0.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "\n",
    "optimizer = torch.optim.Adam(model0.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_examples, valid_examples, embvec, TEXT, LABEL, device, model, batch_size, optimizer, n_epochs):\n",
    "\n",
    "\n",
    "    # Count the number of words and sentences.\n",
    "    n_tokens_train = 0\n",
    "    n_sentences_train = 0\n",
    "    for ex in train_examples:\n",
    "        n_tokens_train += len(ex.text) + 2\n",
    "        n_sentences_train += 1\n",
    "    n_tokens_valid = 0       \n",
    "    for ex in valid_examples:\n",
    "        n_tokens_valid += len(ex.text)\n",
    "\n",
    "\n",
    "    \n",
    "    n_batches = np.ceil(n_sentences_train / batch_size)\n",
    "\n",
    "    mean_n_tokens = n_tokens_train / n_batches\n",
    "\n",
    "    train_iterator = torchtext.data.BucketIterator(\n",
    "        train_examples,\n",
    "        device=device,\n",
    "        batch_size=batch_size,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        repeat=False,\n",
    "        train=True,\n",
    "        sort=True)\n",
    "\n",
    "    valid_iterator = torchtext.data.BucketIterator(\n",
    "        valid_examples,\n",
    "        device=device,\n",
    "        batch_size=64,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        repeat=False,\n",
    "        train=False,\n",
    "        sort=True)\n",
    "\n",
    "    train_batches = list(train_iterator)\n",
    "    valid_batches = list(valid_iterator)\n",
    "\n",
    "    n_labels = len(LABEL.vocab)\n",
    "\n",
    "    history = defaultdict(list)    \n",
    "\n",
    "   \n",
    "\n",
    "    for i in range(1, n_epochs + 1):\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        loss_sum = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch in train_batches:\n",
    "\n",
    "            # Compute the output and loss.\n",
    "            loss = model(batch.text, batch.label)  / mean_n_tokens\n",
    "\n",
    "            optimizer.zero_grad()            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        train_loss = loss_sum / n_batches\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        # Evaluate on the validation set.\n",
    "        if i % 1 == 0:\n",
    "            stats = defaultdict(Counter)\n",
    "\n",
    "            t1 = time.time()\n",
    "            print(f'Epoch {i}: train loss = {train_loss:.4f}, time = {t1-t0:.4f}')\n",
    "\n",
    "    # After the final evaluation, we print more detailed evaluation statistics, including\n",
    "    # precision, recall, and F-scores for the different types of named entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 0.0623, time = 16.2841\n",
      "Epoch 2: train loss = 0.0631, time = 16.1392\n",
      "Epoch 3: train loss = 0.0657, time = 16.1092\n",
      "Epoch 4: train loss = 0.0646, time = 16.1398\n",
      "Epoch 5: train loss = 0.0650, time = 16.1308\n",
      "Epoch 6: train loss = 0.0650, time = 16.1051\n",
      "Epoch 7: train loss = 0.0630, time = 16.1076\n",
      "Epoch 8: train loss = 0.0623, time = 16.1172\n",
      "Epoch 9: train loss = 0.0623, time = 16.1317\n",
      "Epoch 10: train loss = 0.0620, time = 16.1472\n",
      "Epoch 11: train loss = 0.0626, time = 16.1464\n",
      "Epoch 12: train loss = 0.0635, time = 16.1333\n",
      "Epoch 13: train loss = 0.0629, time = 16.1508\n",
      "Epoch 14: train loss = 0.0626, time = 16.1351\n",
      "Epoch 15: train loss = 0.0628, time = 16.1565\n",
      "Epoch 16: train loss = 0.0622, time = 16.0859\n",
      "Epoch 17: train loss = 0.0618, time = 16.1368\n",
      "Epoch 18: train loss = 0.0614, time = 16.1593\n",
      "Epoch 19: train loss = 0.0623, time = 16.0963\n",
      "Epoch 20: train loss = 0.0620, time = 16.1048\n"
     ]
    }
   ],
   "source": [
    "train(train_examples, valid_examples, embvec, TEXT, LABEL, device, model0, batch_size, optimizer,n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model0.state_dict(), '/home/pding/OneDrive/kph/kph/lstm1_85crf_620.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model0.state_dict(), '/home/pding/OneDrive/kph/kph/lstm2cr688.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNNCRFTagger:\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([384, 300]) from checkpoint, the shape in current model is torch.Size([512, 300]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.weight_ih_l0_reverse: copying a param with shape torch.Size([384, 300]) from checkpoint, the shape in current model is torch.Size([512, 300]).\n\tsize mismatch for rnn.weight_hh_l0_reverse: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l0_reverse: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l0_reverse: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-93ede9092dd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/pding/OneDrive/kph//kph/lstmcrf.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/kph2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m    847\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RNNCRFTagger:\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([384, 300]) from checkpoint, the shape in current model is torch.Size([512, 300]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.weight_ih_l0_reverse: copying a param with shape torch.Size([384, 300]) from checkpoint, the shape in current model is torch.Size([512, 300]).\n\tsize mismatch for rnn.weight_hh_l0_reverse: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l0_reverse: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l0_reverse: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([512])."
     ]
    }
   ],
   "source": [
    "model0.load_state_dict(torch.load('/home/pding/OneDrive/kph/kph/lstmcrf.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kphext2(sentences,tags):\n",
    "    kph = []\n",
    "    for i in range(len(sentences)):\n",
    "        s0 = svoc.tokenizer(sentences[i])\n",
    "        s1 = [tok.text for tok in s0]\n",
    "        t1 = tags[i]\n",
    "        k1 = []\n",
    "        for j in range(len(s1)):\n",
    "            start = j\n",
    "            if t1[j] == 'B':\n",
    "                sti = 0\n",
    "                stop = j+1\n",
    "                while sti == 0:\n",
    "                    try: \n",
    "                        kt = str(t1[stop])\n",
    "                        if kt == 'I':\n",
    "                            stop = stop+1\n",
    "                        else:\n",
    "                            k2 = str(s0[start:stop])\n",
    "                            k1.append(k2)\n",
    "                            sti =1\n",
    "                    except(IndexError):\n",
    "                        k2 = s0[start:stop]\n",
    "                        k1.append(k2)\n",
    "                        sti =1\n",
    "                k2 = str(s1[j])\n",
    "        kph.append(k1)\n",
    "    return kph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaltest2(df_val, df_val_k, model):\n",
    "    # This method applies the trained model to a list of sentences.\n",
    "    examples = []\n",
    "    for sen in df_val.SRC:\n",
    "        words = tokenizersrc(sen)\n",
    "        labels = ['O']*len(words) # placeholder\n",
    "        examples.append(torchtext.data.Example.fromlist([words, labels], fields))\n",
    "    dataset = torchtext.data.Dataset(examples, fields)\n",
    "\n",
    "    iterator = torchtext.data.Iterator(\n",
    "        dataset,\n",
    "        device=device,\n",
    "        batch_size=1,\n",
    "        repeat=False,\n",
    "        train=False,\n",
    "        sort=False)\n",
    "\n",
    "    # Apply the trained model to all batches.\n",
    "    out = []\n",
    "    model.eval()\n",
    "    for batch in iterator:\n",
    "        # Call the model's predict method. This returns a list of NumPy matrix\n",
    "        # containing the integer-encoded tags for each sentence.\n",
    "        predicted = model.predict(batch.text)\n",
    "\n",
    "        # Convert the integer-encoded tags to tag strings.\n",
    "        #for tokens, pred_sen in zip(sentences, predicted):\n",
    "        for tokens, pred_sen in zip(batch.text.view(1,-1), predicted):\n",
    "            out.append([LABEL.vocab.itos[pred_id] for _, pred_id in zip(tokens, pred_sen[1:])])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = evaltest2(df_val, df_val_k, model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagperct(df_val,out):\n",
    "    tp = np.empty(len(out))\n",
    "    for i in range(len(df_val.index)):\n",
    "        trg = tokenizertrg(df_val.iloc[i,1])\n",
    "        total = 0\n",
    "        for x in trg:\n",
    "            if x != 'O':\n",
    "                total = total+1\n",
    "        matched = 0\n",
    "        for j in range(total):\n",
    "            if trg[j] != 'O':\n",
    "                if trg[j]== out[i][j]:\n",
    "                    matched = matched +1\n",
    "        p = matched/total\n",
    "        tp[i] = p\n",
    "    return tp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokperct(df_val,out):\n",
    "    tp = np.empty(len(out))\n",
    "    for i in range(len(df_val.index)):\n",
    "        trg = tokenizertrg(df_val.iloc[i,1])\n",
    "        total = 0\n",
    "        for x in trg:\n",
    "            total = total+1\n",
    "        matched = 0\n",
    "        for j in range(total):\n",
    "            if trg[j]== out[i][j]:\n",
    "                matched = matched +1\n",
    "        p = matched/total\n",
    "        tp[i] = p\n",
    "    return tp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outags2 = kphext2(sentences,tagss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kphperct(df_val_k,out):\n",
    "    tp = np.empty(len(out))\n",
    "    for i in range(len(df_val_k.index)):\n",
    "        ktrg = df_val_k.iloc[i,2]\n",
    "        pred = kphext2([df_val_k.iloc[i,0]],[out[i]])\n",
    "        k = 0\n",
    "        for kp in ktrg:\n",
    "            if str(kp).lower() in [str(x).lower() for x in pred[0]]:\n",
    "                k = k+1\n",
    "        tp[i] = k/df_val_k.iloc[i,3]\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp1 = tokperct(df_val,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [df_val_k.iloc[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9381363796103301"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttp1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp2 = tagperct(df_val,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14402059837551062"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttp2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp3 = kphperct(df_val_k,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( out2, open( \"/home/pding/OneDrive/kph/kph/testresults.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521348910997703"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttp3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117608400027607"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttp3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in trg:\n",
    "    if x != 'O':\n",
    "        total = total+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B O O B O O O O O O O O O O B B O O O O O O O O O O O O O O B O O O O O O O O O O O O O O O O O O O O O B O O B B O O O O O O O O O O O O O O O O O O O O O O O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B O O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B B O O O O O O O O O O O O O O O O O O O O O O O O B O O B O O O O O O O O O O O O O O O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.iloc[1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x is True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kph2",
   "language": "python",
   "name": "kph2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
